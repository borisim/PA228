{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "# from torchview import draw_graph\n",
    "from network import SampleModel\n",
    "from dataset import SampleDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from pa228_tools import train, validate\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing with cuda!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Computing with {}!'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_loss_prep(yb, dev): # takes batch\n",
    "    label_dict = {\n",
    "        (0, 0, 0) : 0,\n",
    "        (128, 64, 128) : 1,\n",
    "        (70, 70, 70) : 2,\n",
    "        (153, 153, 153) : 3, \n",
    "        (107, 142, 35) : 4,\n",
    "        (70, 130, 180) : 5,\n",
    "        (220, 20, 60) : 6,\n",
    "        (0, 0, 142) : 7\n",
    "        }\n",
    "    \n",
    "    class_masks = torch.zeros(yb.shape[0], 8, yb.shape[1], yb.shape[2])\n",
    "\n",
    "    for color, class_index in label_dict.items():\n",
    "        color_mask = torch.all(yb == torch.tensor(color).view(1, 1, 1, 3).to(dev), dim=-1).float()\n",
    "        class_masks[:, class_index, :, :] = color_mask\n",
    "    \n",
    "    return class_masks\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, dev, opt=None):\n",
    "    print('enter batch')\n",
    "    xb, yb = xb.to(dev), yb.to(dev)\n",
    "    print('loss')\n",
    "    loss = loss_func(model(xb), label_loss_prep(yb, dev))\n",
    "    print('done loss')\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def train(model, train_dl, loss_func, dev, opt):\n",
    "        \n",
    "        model.train()\n",
    "        loss, size = 0, 0\n",
    "        for b_idx, (xb, yb) in tqdm(enumerate(train_dl), total=len(train_dl), leave=False):\n",
    "            print('batching')\n",
    "            b_loss, b_size = loss_batch(model, loss_func, xb, yb, dev, opt)\n",
    "            print('done batching')\n",
    "\n",
    "            loss += b_loss * b_size\n",
    "            size += b_size\n",
    "            \n",
    "        return loss / size\n",
    "    \n",
    "    \n",
    "def validate(model, valid_dl, loss_func, dev, opt=None):\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb, dev) for xb, yb in valid_dl]\n",
    "            )\n",
    "            \n",
    "        return np.sum(np.multiply(losses, nums)) / np.sum(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, batch_size, epochs, trainloader, validloader, loss_fn, optimizer, device):\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs), 'epochs'):\n",
    "        print('training')\n",
    "        loss = train(net, trainloader, loss_fn, device, optimizer)\n",
    "        print('validating')\n",
    "        val_loss = validate(net, validloader, loss_fn, device)\n",
    "\n",
    "        train_losses.append(loss)\n",
    "        validation_losses.append(val_loss)\n",
    "        print(f'epoch {epoch+1}/{epochs}, loss: {loss : .05f}, validation loss: {val_loss:.05f}')\n",
    "\n",
    "      \n",
    "    print('Training finished!')\n",
    "    return train_losses, validation_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing with cuda!\n"
     ]
    },
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. device=\u0001, num_gpus=\u0001\n\nCUDA call was originally invoked at:\n\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n    self.io_loop.start()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n    self._run_once()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n    handle._run()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n    await self.process_one()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n    await dispatch(*args)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n    await result\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n    reply_content = await reply_content\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n    res = shell.run_cell(\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_3741949/3725067675.py\", line 4, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/__init__.py\", line 1478, in <module>\n    _C._initExtension(manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 238, in <module>\n    _lazy_call(_check_capability)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 235, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:306\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     queued_call()\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:174\u001b[0m, in \u001b[0;36m_check_capability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[0;32m--> 174\u001b[0m     capability \u001b[38;5;241m=\u001b[39m get_device_capability(d)\n\u001b[1;32m    175\u001b[0m     major \u001b[38;5;241m=\u001b[39m capability[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:430\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m prop \u001b[38;5;241m=\u001b[39m get_device_properties(device)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prop\u001b[38;5;241m.\u001b[39mmajor, prop\u001b[38;5;241m.\u001b[39mminor\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:448\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid device id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_device_properties(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. device=\u0001, num_gpus=\u0001",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComputing with \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[0;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_device()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:778\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    777\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     _lazy_init()\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:312\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    308\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    309\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA call was originally invoked at:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(orig_traceback)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m             )\n\u001b[0;32m--> 312\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mdelattr\u001b[39m(_tls, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_initializing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. device=\u0001, num_gpus=\u0001\n\nCUDA call was originally invoked at:\n\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n    self.io_loop.start()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n    self._run_once()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n    handle._run()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n    await self.process_one()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n    await dispatch(*args)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n    await result\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n    reply_content = await reply_content\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n    res = shell.run_cell(\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_3741949/3725067675.py\", line 4, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/__init__.py\", line 1478, in <module>\n    _C._initExtension(manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 238, in <module>\n    _lazy_call(_check_capability)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 235, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Computing with {}!'.format(device))\n",
    "\n",
    "torch.cuda.current_device()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# config dictionary\n",
    "config = {\n",
    "'batch_size': 2,\n",
    "'epoch': 1,\n",
    "'num_workers': 1,\n",
    "'dropout': 0.5,\n",
    "'lr': 0.0001,\n",
    "'optimizer':'Adam',\n",
    "'img_size': 128,\n",
    "'n_classes': 2\n",
    "}\n",
    "\n",
    "PATH = Path('{}'.format('data'), 'data_seg_public')\n",
    "img_dir = PATH / 'img'\n",
    "mask_dir = PATH / 'mask'\n",
    "img_files = glob.glob(\"{}/*/*.png\".format(img_dir))\n",
    "mask_files = glob.glob(\"{}/*/*.png\".format(mask_dir))\n",
    "df = pd.DataFrame({'img': img_files, 'mask': mask_files})\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "transforms = A.Compose([\n",
    "                        A.SmallestMaxSize (512),\n",
    "                        A.CenterCrop(512, 1024),\n",
    "                        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                        ToTensorV2(),\n",
    "                        ]   \n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=.3, random_state=2)\n",
    "traindataset, valdataset = SampleDataset(train_df, transforms=transforms), SampleDataset(valid_df, transforms=transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindataset,\n",
    "                    batch_size=config['batch_size'],\n",
    "                    shuffle=False,\n",
    "                    num_workers=config['num_workers'])\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                    batch_size=config['batch_size'],\n",
    "                    shuffle=False,\n",
    "                    num_workers=config['num_workers'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f25a80f9e4e4a5f87a8e797d19c91eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09a48a54775447c8de4dfa9eab7536f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1143 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batching\n"
     ]
    },
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. device=\u0001, num_gpus=\u0001\n\nCUDA call was originally invoked at:\n\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n    self.io_loop.start()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n    self._run_once()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n    handle._run()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n    await self.process_one()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n    await dispatch(*args)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n    await result\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n    reply_content = await reply_content\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n    res = shell.run_cell(\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_3741949/3725067675.py\", line 4, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/__init__.py\", line 1478, in <module>\n    _C._initExtension(manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 238, in <module>\n    _lazy_call(_check_capability)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 235, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:306\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     queued_call()\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:174\u001b[0m, in \u001b[0;36m_check_capability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[0;32m--> 174\u001b[0m     capability \u001b[38;5;241m=\u001b[39m get_device_capability(d)\n\u001b[1;32m    175\u001b[0m     major \u001b[38;5;241m=\u001b[39m capability[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:430\u001b[0m, in \u001b[0;36mget_device_capability\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the cuda capability of a device.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    tuple(int, int): the major and minor cuda capability of the device\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m prop \u001b[38;5;241m=\u001b[39m get_device_properties(device)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prop\u001b[38;5;241m.\u001b[39mmajor, prop\u001b[38;5;241m.\u001b[39mminor\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:448\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid device id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 448\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _get_device_properties(device)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. device=\u0001, num_gpus=\u0001",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# train the network for three epochs\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n\u001b[0;32m---> 13\u001b[0m tr_losses, val_losses \u001b[38;5;241m=\u001b[39m fit(net, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m], trainloader, valloader, loss_fn, optimizer, device)\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(net, batch_size, epochs, trainloader, validloader, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train(net, trainloader, loss_fn, device, optimizer)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidating\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate(net, validloader, loss_fn, device)\n",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dl, loss_func, dev, opt)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b_idx, (xb, yb) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dl), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dl), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatching\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     b_loss, b_size \u001b[38;5;241m=\u001b[39m loss_batch(model, loss_func, xb, yb, dev, opt)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone batching\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m b_loss \u001b[38;5;241m*\u001b[39m b_size\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, dev, opt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_batch\u001b[39m(model, loss_func, xb, yb, dev, opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 3\u001b[0m     xb, yb \u001b[38;5;241m=\u001b[39m xb\u001b[38;5;241m.\u001b[39mto(dev), yb\u001b[38;5;241m.\u001b[39mto(dev)\n\u001b[1;32m      4\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(xb)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot_out\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:312\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    308\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    309\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA call was originally invoked at:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(orig_traceback)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m             )\n\u001b[0;32m--> 312\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mdelattr\u001b[39m(_tls, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_initializing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: device >= 0 && device < num_gpus INTERNAL ASSERT FAILED at \"/opt/conda/conda-bld/pytorch_1712608847532/work/aten/src/ATen/cuda/CUDAContext.cpp\":50, please report a bug to PyTorch. device=\u0001, num_gpus=\u0001\n\nCUDA call was originally invoked at:\n\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n    app.launch_new_instance()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n    app.start()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n    self.io_loop.start()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 195, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/base_events.py\", line 639, in run_forever\n    self._run_once()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/base_events.py\", line 1985, in _run_once\n    handle._run()\n  File \"/home/xboril/miniconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n    await self.process_one()\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n    await dispatch(*args)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n    await result\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n    reply_content = await reply_content\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n    res = shell.run_cell(\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n    result = self._run_cell(\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n    result = runner(coro)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_3741949/3725067675.py\", line 4, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/__init__.py\", line 1478, in <module>\n    _C._initExtension(manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 238, in <module>\n    _lazy_call(_check_capability)\n  File \"/home/xboril/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py\", line 235, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "net = SampleModel(num_class=8)\n",
    "# input_sample = torch.zeros((1, 512, 1024))\n",
    "# draw_network_architecture(net, input_sample)\n",
    "\n",
    "# define optimizer and learning rate\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=config['lr'])\n",
    "\n",
    "# define loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=2)\n",
    "\n",
    "# train the network for three epochs\n",
    "print(device)\n",
    "tr_losses, val_losses = fit(net, config['batch_size'], config['epoch'], trainloader, valloader, loss_fn, optimizer, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
