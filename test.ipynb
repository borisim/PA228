{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def ishow(img,\n",
    "          cmap='viridis',\n",
    "          title='',\n",
    "          fig_size=(8,6),\n",
    "          colorbar=False,\n",
    "          interpolation='none'):\n",
    "    ' Function `ishow` displays an image in a new window. '\n",
    "    \n",
    "    if img.min() < 0:\n",
    "        img -= img.min()\n",
    "        img /= img.max()\n",
    "    \n",
    "    extent = (0, img.shape[1], img.shape[0], 0)\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    pcm = ax.imshow(img,\n",
    "              extent=extent,\n",
    "              cmap=cmap,\n",
    "              interpolation=interpolation)\n",
    "    \n",
    "    ax.set_frame_on(False)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    if colorbar:\n",
    "        \n",
    "        fig.colorbar(pcm, orientation='vertical')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "PATH = Path('data', 'data_seg_public')\n",
    "town_dir = PATH / 'img'\n",
    "mask_dir = PATH / 'mask'\n",
    "# [ len(list(img_dir.iterdir())) for img_dir in sorted(list(town_dir.iterdir()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ len(list(img_dir.iterdir())) for img_dir in sorted(list(mask_dir.iterdir()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# samples = []\n",
    "# n_samples = len(list(img_dir.glob('*')))\n",
    "# towns = sorted(list(town_dir.iterdir()))\n",
    "# img_files = [list(img.iterdir()) for img in towns]\n",
    "# img_files = sorted([item for sublist in img_files for item in sublist])\n",
    "# ann_files = list(ann_dir.iterdir())\n",
    "# for img_path, ann_path in zip(img_files, ann_files):\n",
    "#     # Create a dictionary for the current sample\n",
    "#     sample = {\n",
    "#         'img_path': img_path,\n",
    "#         'ann_path': ann_path\n",
    "#     }\n",
    "#     # Append the dictionary to the samples list\n",
    "#     samples.append(sample)\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(samples)\n",
    "# df.loc[0]['ann_path']\n",
    "# img_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "transforms_train = A.Compose([\n",
    "                        #  augmentation \n",
    "                        #  A.ColorJitter(brightness=.5, contrast=.5, saturation=.5, hue=.1),\n",
    "                        #  A.GaussNoise(),\n",
    "                        #  A.HorizontalFlip(p=0.5),\n",
    "                        #  A.ShiftScaleRotate(rotate_limit=30, p=1, border_mode=0, value=0, mask_value=3),\n",
    "                        #  A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "                            \n",
    "                        #  # preprocessing\n",
    "                        #  A.SmallestMaxSize (1024),\n",
    "                        #  A.CenterCrop(512, 1024),\n",
    "                        #  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                        #  ToTensorV2(),\n",
    "                        ]   \n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import SampleDataset\n",
    "from network import SampleModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m SampleModel(num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m     11\u001b[0m IDX \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2285\u001b[39m\n\u001b[0;32m---> 12\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[43mtraindataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mIDX\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# pred = model(x)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwtf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/school/pa228/project/Project_Template/PROJCODE_UCO/dataset.py:30\u001b[0m, in \u001b[0;36mSampleDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     28\u001b[0m transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image\u001b[38;5;241m=\u001b[39mimg, mask\u001b[38;5;241m=\u001b[39mann)\n\u001b[1;32m     29\u001b[0m res_img \u001b[38;5;241m=\u001b[39m transformed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 30\u001b[0m res_mask \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_img, res_mask\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "\n",
    "img_files = glob.glob(\"{}/*/*.png\".format(town_dir))\n",
    "mask_files = glob.glob(\"{}/*/*.png\".format(mask_dir))\n",
    "df = pd.DataFrame({'img': img_files, 'mask': mask_files})\n",
    "train_df, valid_df = train_test_split(df, test_size=.3, random_state=2)\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=.3, random_state=2)\n",
    "traindataset = SampleDataset(dataset_df=train_df, transforms=transforms_train)\n",
    "\n",
    "\n",
    "model = SampleModel(num_class=8)\n",
    "IDX = 2285\n",
    "x, y = traindataset[IDX]\n",
    "# pred = model(x)\n",
    "print(\"wtf\")\n",
    "ishow(x)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
